<sect>Symbolic Systems (GOFAI)
<label id="Symbolic Systems (GOFAI)">
    <p>
	Traditionally AI was based around the ideas of logic, rule
	systems, linguistics, and the concept of rationality.  At its
	roots are programming languages such as Lisp and Prolog.
	Expert systems are the largest successful example of this
	paradigm.  An expert system consists of a detailed knowledge
	base and a complex rule system to utilize it.  Such systems
	have been used for such things as medical diagnosis support
	and credit checking systems.

     
    <sect1>AI class/code libraries
    <p>

    These are libraries of code or classes for use in programming within
    the artificial intelligence field.  They are not meant as stand alone
    applications, but rather as tools for building your own applications.
    
    <descrip>

    <label id="ACL2">
    <tag/ACL2/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.cliki.net/ACL2" 
                name="www.cliki.net/ACL2">
        </itemize>

        ACL2 (A Computational Logic for Applicative Common Lisp) is a theorem
        prover for industrial applications. It is both a mathematical logic and
        a system of tools for constructing proofs in the logic.  ACL2 works
        with GCL (GNU Common Lisp).


    <label id="AI Kernel">
    <tag/AI Kernel/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://aikernel.sourceforge.net/"
                name="aikernel.sourceforge.net">
            <item>Sourceforge site: <htmlurl 
                url="http://sourceforge.net/projects/aikernel/"
                name="sourceforge.net/projects/aikernel/">
        </itemize>

        The AI Kernel is a re-usable artificial intelligence engine that uses
        natural language processing and an Activator / Context model to allow
        multi tasking between installed cells.


      <label id="AI Search II"> 
      <tag/AI Search II/
    <itemize>
	    <item>WEB site: <htmlurl
            url="http://www.neiu.edu/~kwtracy/ooai-book/">
    </itemize>
       
	Basically, the library offers the programmer a set of search
	algorithms that may be used to solve all kind of different
	problems. The idea is that when developing problem solving software
	the programmer should be able to concentrate on the representation of
	the problem to be solved and should not need to bother with the
	implementation of the search algorithm that will be used to actually
	conduct the search. This idea has been realized by the implementation
	of a set of search classes that may be incorporated in other software
	through <bf>C++</bf>'s features of derivation and inheritance.  The
	following search algorithms have been implemented:
	

        <itemize>
	<item>depth-first tree and graph search.</item>
	<item>breadth-first tree and graph search.</item>
	<item>uniform-cost tree and graph search.</item>
	<item>best-first search.</item>
	<item>bidirectional depth-first tree and graph search.</item>
	<item>bidirectional breadth-first tree and graph search.</item>
	<item>AND/OR depth tree search.</item>
	<item>AND/OR breadth tree search.</item>
        </itemize>

    
        This library has a corresponding book, "<htmlurl
        url="http://www.neiu.edu/~kwtracy/ooai-book/"
        name="Object-Oriented Artificial Intelligence, Using C++">".


    <label id="Alchemy">
    <tag/Alchemy/
        <itemize>
            <item>Web site: <htmlurl
                url="http://alchemy.cs.washington.edu/">
        </itemize>

        Alchemy is a software package providing a series of algorithms for
        statistical relational learning and probabilistic logic inference,
        based on the Markov logic representation. Alchemy allows you to easily
        develop a wide range of AI applications, including:

        <itemize>
          <item>Collective classification</item>
          <item>Link prediction</item>
          <item>Entity resolution</item>
          <item>Social network modeling</item>
          <item>Information extraction</item>
        </itemize>


    <label id="Aleph">
    <tag/Aleph/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://web.comlab.ox.ac.uk/oucl/research/areas/machlearn/Aleph/"
                name="web.comlab.ox.ac.uk/oucl/research/areas/machlearn/Aleph/">
        </itemize>

        This document provides reference information on A Learning Engine for
        Proposing Hypotheses (Aleph). Aleph is an Inductive Logic Programming
        (ILP) system. Aleph is intended to be a prototype for exploring ideas.
        Aleph is an ILP algorithm implemented in Prolog by Dr Ashwin
        Srinivasan at the Oxford University Computing Laboratory, and is
        written specifically for compilation with the YAP Prolog compiler


    <label id="CBR Microprograms">
    <tag/Microprograms/
        <itemize>
            <item>Web site: <htmlurl
                url="http://www.cs.indiana.edu/~leake/cbr/code/">
        </itemize>

        A collection of case-based reasoning "micro" versions of dissertation
        programs that were developed for pedagogical purposes. These programs
        are meant to distill key aspects of the original programs into a form
        that can be easily understood, modified, and extended.


    <label id="Chess In List">
    <tag/Chess In Lisp (CIL)/
    <itemize>
      <item>Web site: *found as part of the CLOCC archive at: <htmlurl
                url="http://clocc.sourceforge.net/"
                name="clocc.sourceforge.net">
     </itemize>
     
      The CIL (Chess In Lisp) foundation is a Common Lisp
      implementaion of all the core functions needed for development
      of chess applications.  The main purpose of the CIL project is
      to get AI researchers interested in using Lisp to work in the
      chess domain.
    

    <label id="ConceptNet">
    <tag/ConceptNet/
        <itemize>
            <item>Web site: <htmlurl
                url="http://conceptnet.media.mit.edu/">
            <item>Old Web site: <htmlurl
                url="http://web.media.mit.edu/~hugo/conceptnet/">
        </itemize>
        
	ConceptNet aims to give computers access to common-sense knowledge, the
	kind of information that ordinary people know but usually leave
	unstated. The data in ConceptNet was collected from ordinary people who
	contributed it over the Web. ConceptNet represents this data in the
	form of a semantic network, and makes it available to be used in
	natural language processing and intelligent user interfaces.

	This API provides Python code with access to both ConceptNet 3 and the
	development database that will become ConceptNet 4, and the natural
	language tools necessary to work with it. It uses Django for
	interacting with the database.


    <label id="FFLL">
    <tag/FFLL/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://ffll.sourceforge.net/" 
                name="ffll.sourceforge.net">
        </itemize>

        The Free Fuzzy Logic Library (FFLL) is an open source fuzzy logic class
        library and API that is optimized for speed critical applications, such
        as video games. FFLL is able to load files that adhere to the  IEC
        61131-7 standard.


    <label id="FLiP">
    <tag/FLiP/
        <itemize>
            <item>Web site: <htmlurl
                url="http://staff.washington.edu/jon/flip/www/">
        </itemize>

	Flip is a logical framework written in Python. A logical framework is a
	library for defining logics and writing applications such as theorem
	provers. The checker can use different logics; Flip comes with several.
	You can add another logic, or add axioms and derived rules, by writing
	a module in Python. Python is both the object language and the
	metalanguage. Formulas, inference rules, and entire proofs are Python
	expressions. Prover commands are Python functions.


    <label id="Fuzzy sets for Ada">
    <tag/Fuzzy sets for Ada/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.dmitry-kazakov.de/ada/fuzzy.htm"
                name="www.dmitry-kazakov.de/ada/fuzzy.htm">
            <item>Freshmeat: <htmlurl 
                url="http://freshmeat.net/projects/fuzzy/"
                name="freshmeat.net/projects/fuzzy/">
        </itemize>
        
        Fuzzy sets for Ada is a library providing implementations of confidence
        factors with the operations not, and, or, xor, +, and *, classical
        fuzzy sets with the set-theoretic operations and the operations of the
        possibility theory, intuitionistic fuzzy sets with the operations on
        them, fuzzy logic based on the intuitionistic fuzzy sets and the
        possibility theory; fuzzy numbers, both integer and floating-point with
        conventional arithmetical operations, and linguistic variables and sets
        of linguistic variables with operations on them.  String-oriented I/O
        is supported.


    <label id="HTK">
    <tag/HTK/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://htk.eng.cam.ac.uk/" 
                name="htk.eng.cam.ac.uk">
        </itemize>

        The Hidden Markov Model Toolkit (HTK) is a portable toolkit for
        building and manipulating hidden Markov models.  HTK consists of a set
        of library modules and tools available in C source form. The tools
        provide sophisticated facilities for speech analysis, HMM training,
        testing and results analysis. The software supports HMMs using both
        continuous density mixture Gaussians and discrete distributions and can
        be used to build complex HMM systems.  The HTK release contains
        extensive documentation and examples.


    <label id="JCK">
    <tag/JCK/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.pms.informatik.uni-muenchen.de/software/jack/"
                name="www.pms.informatik.uni-muenchen.de/software/jack/">
        </itemize>

        JCK is a new library providing constraint programming and search for
        Java.
        <itemize>
        JCK consists of three components:
            <item>
             - JCHR: Java Constraint Handling Rules.
                     A high-level language to write constraint solvers.
            <item>
             - JASE: Java Abstract Search Engine.
                     A generic search engine for JCHR to solve constraint 
                     problems.
            <item>
             - VisualCHR:
                     An interactive tool to visualize JCHR computations.
        </itemize>
        Source and documentation available from link above.


    <label id="KANREN">
    <tag/KANREN/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://kanren.sourceforge.net/"
                name="kanren.sourceforge.net">
        </itemize>

        KANREN is a declarative logic programming system with first-class
        relations, embedded in a pure functional subset of Scheme. The system
        has a set-theoretical semantics, true unions, fair scheduling,
        first-class relations, lexically-scoped logical variables, depth-first
        and iterative deepening strategies. The system achieves high
        performance and expressivity without cuts.

    
    <label id="LK">
    <tag/LK/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.cs.utoronto.ca/&tilde;neto/research/lk/" 
                name="www.cs.utoronto.ca/&tilde;neto/research/lk/">
        </itemize>

        LK is an implementation of the Lin-Kernighan heuristic for the
        Traveling Salesman Problem and for the minimum weight perfect matching
        problem. It is tuned for 2-d geometric instances, and has been applied
        to certain instances with up to a million cities. Also included are
        instance generators and Perl scripts for munging TSPLIB instances. 

        This implementation introduces ``efficient cluster compensation'', an
        experimental algorithmic technique intended to make the Lin-Kernighan
        heuristic more robust in the face of clustered data.


    <label id="LingPipe">
    <tag/LingPipe/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.alias-i.com/lingpipe/">
        </itemize>
    
        LingPipe is a state-of-the-art suite of natural language processing
        tools written in Java that performs tokenization, sentence detection,
        named entity detection, coreference resolution, classification,
        clustering, part-of-speech tagging, general chunking, fuzzy dictionary
        matching. 


    <label id="Logfun">
    <tag/Logfun/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.irisa.fr/lande/ferre/logfun/">
        </itemize>

        Logfun is a library of logic functors. A logic functor is a
        function that can be applied to zero, one or several logics so as
        to produce a new logic as a combination of argument logics. Each
        argument logic can itself be built by combination of logic
        functors. The signature of a logic is made of a parser and a
        printer of formulas, logical operations such as a theorem prover
        for entailment between formulas, and more specific operations
        required by Logical Information Systems (LIS). Logic functors can
        be concrete domains like integers, strings, or algebraic
        combinators like product or sum of logics.

        Logic functors are coded as Objective Caml modules. A logic
        semantics is associated to each of these logic functors. This
        enables to define properties of logics like the consistency and
        completeness of the entailment prover, and to prove under which
        conditions a generated entailement prover satisfies these
        properties given the properties of argument logics.


    <label id="Loom">
    <tag/Loom/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.isi.edu/isd/LOOM/">
        </itemize>

        * Note: Loom has been succeeded by <ref id="PowerLoom">.

        Loom is a language and environment for constructing intelligent
        applications. The heart of Loom is a knowledge representation system
        that is used to provide deductive support for the declarative portion
        of the Loom language. Declarative knowledge in Loom consists of
        definitions, rules, facts, and default rules. A deductive engine called
        a classifier utilizes forward-chaining, semantic unification and
        object-oriented truth maintainance technologies in order to compile the
        declarative knowledge into a network designed to efficiently support
        on-line deductive query processing.

        The Loom system implements a logic-based pattern matcher that drives a
        production rule facility and a pattern-directed method dispatching
        facility that supports the definition of object-oriented methods. The
        high degree of integration between Loom's declarative and procedural
        components permits programmers to utilize logic programming, production
        rule, and object-oriented programming paradigms in a single
        application. Loom can also be used as a deductive layer that overlays
        an ordinary CLOS network. In this mode, users can obtain many of the
        benefits of using Loom without impacting the function or performance of
        their CLOS-based applications.


    <label id="maxent">
    <tag/maxent/
        <itemize>
            <item>Python/C++ version: <htmlurl 
                url="http://homepages.inf.ed.ac.uk/lzhang10/maxent_toolkit.html"
                name="http://homepages.inf.ed.ac.uk/lzhang10/maxent_toolkit.html">
            <item>Java version: <htmlurl 
                url="http://maxent.sourceforge.net/"
                name="maxent.sourceforge.net">
         </itemize>

        The Maximum Entropy Toolkit provides a set of tools and library for
        constructing maximum entropy (maxent) models in either Python or C++.
        It features conditional maximum entropy models, L-BFGS and GIS
        parameter estimation, Gaussian Prior smoothing, a C++ API, a Python
        extension module, a command line utility, and good documentation. A
        Java version is also available.


    <label id="Nyquist"> 
    <tag/Nyquist/
	<itemize> 
            <item>Web site: <htmlurl
                url="http://www-2.cs.cmu.edu/~music/nyquist/" 
                name="www-2.cs.cmu.edu/~music/nyquist/">
        </itemize>

        The Computer Music Project at CMU is developing computer music
        and interactive performance technology to enhance human musical
        experience and creativity. This interdisciplinary effort draws
        on Music Theory, Cognitive Science, Artificial Intelligence and
        Machine Learning, Human Computer Interaction, Real-Time Systems,
        Computer Graphics and Animation, Multimedia, Programming
        Languages, and Signal Processing. A paradigmatic example of
        these interdisciplinary efforts is the creation of interactive
        performances that couple human musical improvisation with
        intelligent computer agents in real-time.
     

    <label id="OpenCyc">
    <tag/OpenCyc/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.opencyc.org/"
                name="www.opencyc.org">
            <item>Alt Web site: <htmlurl 
                url="http://sourceforge.net/projects/opencyc/"
                name="sourceforge.net/projects/opencyc/">
        </itemize>

        OpenCyc is the open source version of Cyc, the largest and most
        complete general knowledge base and commonsense reasoning engine. An
        ontology based on 6000 concepts and 60000 assertions about them.


    <label id="PowerLoom">
    <tag/PowerLoom/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.isi.edu/isd/LOOM/PowerLoom/">
        </itemize>

        PowerLoom is the successor to the <ref id="Loom"> knowledge
        representation system. It provides a language and environment for
        constructing intelligent, knowledge-based applications. PowerLoom uses
        a fully expressive, logic-based representation language (a variant of
        KIF). It uses a natural deduction inference engine that combines
        forward and backward chaining to derive what logically follows from the
        facts and rules asserted in the knowledge base. While PowerLoom is not
        a description logic, it does have a description classifier which uses
        technology derived from the Loom classifier to classify descriptions
        expressed in full first order predicate calculus (see paper). PowerLoom
        uses modules as a structuring device for knowledge bases, and
        ultra-lightweight worlds to support hypothetical reasoning.

        To implement PowerLoom we developed a new programming language called
        <ref id="STELLA">, which is a Strongly Typed, Lisp-like LAnguage that
        can be translated into Lisp, C++ and Java. PowerLoom is written in
        STELLA and therefore available in Common-Lisp, C++ and Java versions. 


    <label id="PyCLIPS">
    <tag/PyCLIPS/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://pyclips.sourceforge.net/web/">
        </itemize>

        PyCLIPS is an extension module for the Python language that embeds full
        CLIPS functionality in Python applications. This means that you can
        provide Python with a strong, reliable, widely used and well documented
        inference engine.


    <label id="PyIE">
    <tag/PyIE/
        <itemize>
            <item>Subversion repository: <htmlurl
                url="https://www.dfwpython.org/repo/Projects/PyIE/">
        </itemize>

	PyIE is a hypothesis based, agenda driven, object oriented inference
	engine written in Python. Inferencing modes include back chaining,
	opportunistic forward chaining and explicit forward chaining. The
	first-class object base supports metaclasses, classes, objects and
	multiple, dynamic inheritance.  All objects are first class objects and
	all attributes are slot values, i.e. data members attached to some
	object.

	PyIE uses a TMS (truth maintenance system) for first level (condition
	change) non-monotonic reasoning. User defined metaclasses are being
	explored to support second level (belief change) non-monotonic
	reasoning.


    <label id="Pyke">
    <tag/Pyke/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://pyke.sourceforge.net/">
        </itemize>

        Pyke is a knowledge-based inference engine (expert system) written in
        100% python that can:

        <itemize>
          <item> Do both forward-chaining (data driven) and backward-chaining
          (goal directed) inferencing.
          <itemize>
            <item> Pyke may be embedded into any python program.
          </itemize>

          <item> Automatically generate python programs by assembling
          individual python functions into complete call graphs.

          <itemize>

            <item> This is done through a unique design where the individual
            python functions are attached to backward-chaining rules.

            <item> Unlike other approaches to code reuse (e.g. Zope adapters
            and generic functions), this allows the inference engine to ensure
            that all of the function's requirements are completely satisfied,
            by examining the entire call graph down to the leaves, before any
            of the functions are executed.

            <item> This is an optional feature. You don't need to use it if you
            just want the inferencing capability by itself.

            </itemize>
        </itemize>


    <label id="python-dlp">
    <tag/python-dlp/
        <itemize>
            <item>Web site: <htmlurl
                url="http://code.google.com/p/python-dlp/">
        </itemize>

	    python-dlp aims to be a contemporary expert system based on the
	    Semantic Web technologies. Traditionally, expert systems are an
	    application of computing and artificial intelligence with the aim
	    of supporting software that attempts to reproduce the deterministic
	    behavior of one or more human experts in a specific problem domain. 
	    It utilizes the efficient RETE_UL algorithm as the 'engine' for the
	    expert system


    <label id="Reverend">
    <tag/Reverend/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://sourceforge.net/projects/reverend/">
        </itemize>
    
        Reverned is a general purpose Bayesian classifier written in Python. It
        is designed to be easily extended to any application domain.


    <label id="Screamer">
    <tag/Screamer/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.cis.upenn.edu/&tilde;screamer-tools/home.html"
                name="www.cis.upenn.edu/&tilde;screamer-tools/home.html">
            <item>Latest version is part of CLOCC: <htmlurl 
                url="http://clocc.sourceforge.net/"
                name="clocc.sourceforge.net">
        </itemize>
     
      Screamer is an extension of Common Lisp that adds support for
      nondeterministic programming. Screamer consists of two
      levels. The basic nondeterministic level adds support for
      backtracking and undoable side effects.  On top of this
      nondeterministic substrate, Screamer provides a comprehensive
      constraint programming language in which one can formulate and
      solve mixed systems of numeric and symbolic
      constraints. Together, these two levels augment Common Lisp with
      practically all of the functionality of both Prolog and
      constraint logic programming languages such as CHiP and CLP(R).
      Furthermore, Screamer is fully integrated with Common
      Lisp. Screamer programs can coexist and interoperate with other
      extensions to Common Lisp such as CLOS, CLIM and Iterate.


    <label id="Shogun">
    <tag/Shogun/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.shogun-toolbox.org/">
        </itemize>

        The machine learning toolbox's focus is on large scale kernel methods
        and especially on Support Vector Machines (SVM) [1]. It provides a
        generic SVM object interfacing to several different SVM
        implementations, among them the state of the art LibSVM [2] and
        SVMLight [3]. Each of the SVMs can be combined with a variety of
        kernels. The toolbox not only provides efficient implementations of the
        most common kernels, like the Linear, Polynomial, Gaussian and Sigmoid
        Kernel but also comes with a number of recent string kernels as e.g.
        the Locality Improved [4], Fischer [5], TOP [6], Spectrum [7], Weighted
        Degree Kernel (with shifts) [8] [9] [10]. For the latter the efficient
        LINADD [10] optimizations are implemented. Also SHOGUN offers the
        freedom of working with custom pre-computed kernels. One of its key
        features is the combined kernel which can be constructed by a weighted
        linear combination of a number of sub-kernels, each of which not
        necessarily working on the same domain. An optimal sub-kernel weighting
        can be learned using Multiple Kernel Learning [11] [12] [16]. Currently
        SVM 2-class classification and regression problems can be dealt with.
        However SHOGUN also implements a number of linear methods like Linear
        Discriminant Analysis (LDA), Linear Programming Machine (LPM), (Kernel)
        Perceptrons and features algorithms to train hidden markov models. The
        input feature-objects can be dense, sparse or strings and of type
        int/short/double/char and can be converted into different feature
        types. Chains of preprocessors (e.g. substracting the mean) can be
        attached to each feature object allowing for on-the-fly pre-processing.

        SHOGUN is implemented in C++ and interfaces to Matlab(tm), R, Octave
        and Python.


    <label id="SPASS">
    <tag/SPASS/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://spass.mpi-sb.mpg.de/"
                name="spass.mpi-sb.mpg.de">
        </itemize>

        SPASS: An Automated Theorem Prover for First-Order Logic with Equality

        If you are interested in first-order logic theorem proving, the formal
        analysis of software, systems, protocols, formal approaches to AI
        planning, decision procedures, modal logic theorem proving, SPASS may
        offer you the right functionality.


    <label id="ThoughtTreasure">
    <tag/ThoughtTreasure/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.signiform.com/tt/htm/tt.htm" 
                name="www.signiform.com/tt/htm/tt.htm">
        </itemize>
        
        ThoughtTreasure is a project to create a database of commonsense rules
        for use in any application. It consists of a database of a little over
        100K rules and a C API to integrate it with your applications. Python,
        Perl, Java and TCL wrappers are already available.

    <label id="Torch">
    <tag/Torch/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.torch.ch/" 
                name="www.torch.ch">
        </itemize>
        
        Torch is a machine-learning library, written in C++.  Its aim is to
        provide the state-of-the-art of the best algorithms.  It is, and it
        will be, in development forever.
  
        <itemize>
            <item>Many gradient-based methods, including multi-layered
            perceptrons, radial basis functions, and mixtures of experts.  Many
            small "modules" (Linear module, Tanh module, SoftMax module, ...)
            can be plugged together.
            
            <item>Support Vector Machine, for classification and regression.
            
            <item>Distribution package, includes Kmeans, Gaussian Mixture
            Models, Hidden Markov Models, and Bayes Classifier, and classes for
            speech recognition with embedded training.  
            
            <item>Ensemble models such as Bagging and Adaboost.

            <item>Non-parametric models such as K-nearest-neighbors, Parzen
            Regression and Parzen Density Estimator.
             
            <item>
        </itemize>
        
        Torch is an open library whose authors encourage everybody to develop
        new packages to be included in future versions on the official website.

  </descrip>


    <sect1>AI software kits, applications, etc.
    <p>
    
    These are various applications, software kits, etc. meant for research
    in the field of artificial intelligence. Their ease of use will vary,
    as they were designed to meet some particular research interest more
    than as an easy to use commercial package.
    
    <descrip>
       
      <label id="ASA">
      <tag/ASA - Adaptive Simulated Annealing/
	    <itemize> 
            <item>Web site: <htmlurl url="http://www.ingber.com/&num;ASA-CODE" name="www.ingber.com/&num;ASA-CODE">
        	<item>FTP site: <htmlurl url="ftp://ftp.ingber.com/" name="ftp.ingber.com/">
        </itemize>

       
	ASA (Adaptive Simulated Annealing) is a powerful global
	optimization C-code algorithm especially useful for nonlinear and/or
	stochastic systems.
	

        ASA is developed to statistically find the best global fit of a
        nonlinear non-convex cost-function over a D-dimensional space. This
        algorithm permits an annealing schedule for 'temperature' T decreasing
        exponentially in annealing-time k, T = T&lowbar;0 exp(-c k&circ;1/D).
        The introduction of re-annealing also permits adaptation to changing
        sensitivities in the multi-dimensional parameter-space. This annealing
        schedule is faster than fast Cauchy annealing, where T = T&lowbar;0/k,
        and much faster than Boltzmann annealing, where T = T&lowbar;0/ln k.  


    <label id="Babylon"> 
    <tag/Babylon/
        <itemize>
            <item>Archive: <htmlurl 
                url="http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/expert/systems/babylon/">
            <item>(Dead) FTP site: <htmlurl 
                url="ftp://ftp.gmd.de/gmd/ai-research/Software/Babylon/">
        </itemize>
     
      BABYLON is a modular, configurable, hybrid environment for
      developing expert systems. Its features include objects, rules with
      forward and backward chaining, logic (Prolog) and constraints. BABYLON
      is implemented and embedded in Common Lisp.
     
    
    <label id="cfengine">
    <tag/cfengine/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.iu.hio.no/cfengine/" 
                name="www.iu.hio.no/cfengine/">
        </itemize>
        
        Cfengine, or the configuration engine is a very high level language for
        building expert systems which administrate and configure large computer
        networks. Cfengine uses the idea of classes and a primitive form of
        intelligence to define and automate the configuration of large systems
        in the most economical way possible. Cfengine is design to be a part of
        computer immune systems.


    <label id="CLIPS">
    <tag/CLIPS/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://clipsrules.sourceforge.net/">
        </itemize>
      
      CLIPS is a productive development and delivery expert system tool
      which provides a complete environment for the construction of rule
      and/or object based expert systems.  
      
      CLIPS provides a cohesive tool for handling a wide variety of
      knowledge with support for three different programming paradigms:
      rule-based, object-oriented and procedural.  Rule-based programming
      allows knowledge to be represented as heuristics, or "rules of thumb,"
      which specify a set of actions to be performed for a given
      situation. Object-oriented programming allows complex systems to be
      modeled as modular components (which can be easily reused to model
      other systems or to create new components).  The procedural
      programming capabilities provided by CLIPS are similar to capabilities
      found in languages such as C, Pascal, Ada, and LISP.
     

    <label id="Eprover">
    <tag/Eprover/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.eprover.org/"
                name="http://www.eprover.org/">
            <item>Web site: <htmlurl 
                url="http://www4.informatik.tu-muenchen.de/&tilde;schulz/WORK/eprover.html"
                name="http://www4.informatik.tu-muenchen.de/&tilde;schulz/WORK/eprover.html">
        </itemize>

      The E Equational Theorem Prover is a purely equational theorem prover.
      The core proof procedure operates on formulas in clause normal form,
      using a calculus that combines superposition (with selection of negative
      literals) and rewriting. No special rules for non-equational literals
      have been implemented, i.e., resolution is simulated via paramodulation
      and equality resolution. The basic calculus is extended with rules for AC
      redundancy elemination, some contextual simplification, and
      pseudo-splitting. The latest version of E also supports simultaneous
      paramodulation, either for all inferences or for selected inferences.

      E is based on the DISCOUNT-loop variant of the given-clause algorithm,
      i.e. a strict separation of active and passive facts. Proof search in E
      is primarily controlled by a literal selection strategy, a clause
      evaluation heuristic, and a simplification ordering. The prover supports
      a large number of preprogrammed literal selection strategies, many of
      which are only experimental. Clause evaluation heuristics can be
      constructed on the fly by combining various parameterized primitive
      evaluation functions, or can be selected from a set of predefined
      heuristics. Supported term orderings are several parameterized instances
      of Knuth-Bendix-Ordering (KBO) and Lexicographic Path Ordering (LPO). 
  

    <label id="Fool-Fox">
    <tag/FOOL &amp; FOX/
    <itemize>
      <item>Web site: <htmlurl 
                url="http://rhaug.de/fool/" 
                name="rhaug.de/fool/">
      <item>FTP site: <htmlurl 
                url="ftp://ftp.informatik.uni-oldenburg.de/pub/fool/" 
                name="ftp.informatik.uni-oldenburg.de/pub/fool/">
    </itemize>

     
      FOOL stands for the Fuzzy Organizer OLdenburg. It is a result from
      a project at the University of Oldenburg. FOOL is a graphical user
      interface to develop fuzzy rulebases.  FOOL will help you to invent
      and maintain a database that specifies the behavior of a
      fuzzy-controller or something like that.
      

      FOX is a small but powerful fuzzy engine which reads this database,
      reads some input values and calculates the new control value.


    <label id="FreeHAL">
    <tag/FreeHAL/
        <itemize>
            <item>Web site: <htmlurl
                url="http://en.freehal.org/">
        </itemize>

        FreeHAL is a self-learning conversation simulator which uses semantic
        nets to organize its knowledge.

        FreeHAL uses a semantic network, pattern matching, stemmers, part of
        speech databases, part of speech taggers, and Hidden Markov Models.
        Both the online and the download version support TTS.


    <label id="FUF-SURGE">
    <tag/FUF and SURGE/
      <itemize>
        <item>Web site: <htmlurl 
                url="http://www.cs.bgu.ac.il/research/projects/surge/index.htm" 
                name="www.cs.bgu.ac.il/research/projects/surge/index.htm">
        <item>FTP site: <htmlurl 
                url="ftp://ftp.cs.bgu.ac.il/pub/fuf/" 
                name="ftp.cs.bgu.ac.il/pub/fuf/">
      </itemize>
     
      FUF is an extended implementation of the formalism of functional
      unification grammars (FUGs) introduced by Martin Kay specialized to
      the task of natural language generation. It adds the following
      features to the base formalism:
      <itemize>	
        <item>Types and inheritance. 
	    <item>Extended control facilities (goal freezing, intelligent 
                    backtracking). 
	    <item>Modular syntax.
      </itemize>
      These extensions allow the development of large grammars which can be
      processed efficiently and can be maintained and understood more
      easily.  SURGE is a large syntactic realization grammar of English
      written in FUF. SURGE is developed to serve as a black box syntactic
      generation component in a larger generation system that encapsulates a
      rich knowledge of English syntax. SURGE can also be used as a platform
      for exploration of grammar writing with a generation perspective.
     

    <label id="GATE">
    <tag/GATE/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://gate.ac.uk/">
            <item>Alt site: <htmlurl 
                url="http://sourceforge.net/projects/gate">
        </itemize>

      GATE (General Architecture for Text Engineering) is an architecture,
      framework and development environment for developing, evaluating and
      embedding Human Language Technology.

      GATE is made up of three elements:
      <itemize>	
        <item>An architecture describing how language processing systems are
        made up of components.
        <item>A framework (or class library, or SDK), written in Java and
        tested on Linux, Windoze and Solaris.
        <item>A graphical development environment built on the framework. 
      </itemize>


    <label id="Grammar Workbench">
    <tag/The Grammar Workbench/
      <itemize>
        <item>Web site: ??? <htmlurl 
                url="http://www.cs.kun.nl/agfl/" 
                name="www.cs.kun.nl/agfl/">
      </itemize>     

      Seems to be obsolete??? Its gone from the site, though its parent 
      project is still ongoing. 
     
      The Grammar Workbench, or GWB for short, is an environment for the
      comfortable development of Affix Grammars in the AGFL-formalism. Its
      purposes are: 
      <itemize>	
        <item>to allow the user to input, inspect and modify a grammar; 
    	<item>to perform consistency checks on the grammar; 
	    <item>to compute grammar properties; 
	    <item>to generate example sentences; 
	    <item>to assist in performing grammar transformations. 
      </itemize>
     
    
    <label id="GSM Suite">
    <tag/GSM Suite/
        <itemize> 
            <item>Alt site: <htmlurl 
                url="http://www.ibiblio.org/pub/Linux/apps/graphics/draw/" 
                name="www.ibiblio.org/pub/Linux/apps/graphics/draw/">
        </itemize>
  
      The GSM Suite is a set of programs for using Finite State
      Machines in a graphical fashion. The suite consists of programs
      that edit, compile, and print state machines. Included in the
      suite is an editor program, gsmedit, a compiler, gsm2cc, that
      produces a C++ implementation of a state machine, a PostScript
      generator, gsm2ps, and two other minor programs. GSM is licensed
      under the GNU Public License and so is free for your use under
      the terms of that license.


    <label id="Isabelle">
    <tag/Isabelle/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://isabelle.in.tum.de/" 
                name="isabelle.in.tum.de">
        </itemize>

        Isabelle is a popular generic theorem prover developed at Cambridge
        University and TU Munich. Existing logics like Isabelle/HOL provide a
        theorem proving environment ready to use for sizable applications.
        Isabelle may also serve as framework for rapid prototyping of deductive
        systems. It comes with a large library including Isabelle/HOL
        (classical higher-order logic), Isabelle/HOLCF (Scott's Logic for
        Computable Functions with HOL), Isabelle/FOL (classical and
        intuitionistic first-order logic), and Isabelle/ZF (Zermelo-Fraenkel
        set theory on top of FOL).


    <label id="Jess">
    <tag/Jess, the Java Expert System Shell/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://herzberg.ca.sandia.gov/jess/" 
                name="herzberg.ca.sandia.gov/jess/">
        </itemize>
 
      Jess is a clone of the popular CLIPS expert system shell written
      entirely in Java. With Jess, you can conveniently give your
      applets the ability to 'reason'. Jess is compatible with all
      versions of Java starting with version 1.0.2. Jess implements
      the following constructs from CLIPS: defrules, deffunctions,
      defglobals, deffacts, and deftemplates.  


    <label id="learn">
    <tag/learn/
    <itemize>
        <item>Web site: <htmlurl 
            url="http://www.ibiblio.org/pub/Linux/apps/cai/" 
            name="www.ibiblio.org/pub/Linux/apps/cai/">
    </itemize>
      
      Learn is a vocable learning program with memory model. 
     

    <label id="LISA">
    <tag/LISA/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://lisa.sourceforge.net/" 
                name="lisa.sourceforge.net">
        </itemize>

        LISA (Lisp-based Intelligent Software Agents) is a production-rule
        system heavily influenced by JESS (Java Expert System Shell). It has at
        its core a reasoning engine based on the Rete pattern matching
        algorithm. LISA also provides the ability to reason over ordinary CLOS
        objects.


    <label id="Livingstone2">
    <tag/Livingstone2/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://ic.arc.nasa.gov/projects/L2/doc/">
        </itemize>

        Livingstone2 (L2) is a reusable artificial intelligence (AI) software
        system designed to assist spacecraft, life support systems, chemical
        plants or other complex systems in operating robustly with minimal
        human supervision, even in the face of hardware failures or unexpected
        events.


    <label id="NICOLE">
    <tag/NICOLE/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://nicole.sourceforge.net/" 
                name="nicole.sourceforge.net">
        </itemize>

        NICOLE (Nearly Intelligent Computer Operated Language Examiner) is a
        theory or experiment that if a computer is given enough combinations of
        how words, phrases and sentences are related to one another, it could
        talk back to you. It is an attempt to simulate a conversation by
        learning how words are related to other words. A human communicates
        with NICOLE via the keyboard and NICOLE responds back with its own
        sentences which are automatically generated, based on what NICOLE has
        stored in it's database. Each new sentence that has been typed in, and
        NICOLE doesn't know about, is included into NICOLE's database, thus
        extending the knowledge base of NICOLE.
    

    <label id="NLTK">
    <tag/NLTK/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www.nltk.org/"
                name="www.nltk.org">
        </itemize>
        
        NLTK, the Natural Language Toolkit, is a suite of Python libraries and
        programs for symbolic and statistical natural language processing.
        NLTK includes graphical demonstrations and sample data. It is
        accompanied by extensive documentation, including tutorials that
        explain the underlying concepts behind the language processing tasks
        supported by the toolkit.


        NLTK is ideally suited to students who are learning NLP (natural
        language processing) or conducting research in NLP or closely related
        areas, including empirical linguistics, cognitive science, artificial
        intelligence, information retrieval, and machine learning. NLTK has
        been used successfully as a teaching tool, as an individual study tool,
        and as a platform for prototyping and building research systems. 


    <label id="Otter">
    <tag/Otter: An Automated Deduction System/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://www-unix.mcs.anl.gov/AR/otter/"
                name="www-unix.mcs.anl.gov/AR/otter/">
        </itemize>
     
      Our current automated deduction system  Otter is designed to prove
      theorems stated in first-order logic with equality.  Otter's
      inference rules are based on resolution and paramodulation, and it
      includes facilities for term rewriting, term orderings, Knuth-Bendix
      completion, weighting, and strategies for directing and restricting
      searches for proofs.   Otter can also be used as a symbolic
      calculator and has an embedded equational programming system.
     

      <label id="PVS">
      <tag/PVS/
        <itemize>
            <item>Web site: <htmlurl url="http://pvs.csl.sri.com/" name="pvs.csl.sri.com/">
        </itemize>
     
      PVS is a verification system: that is, a specification language
      integrated with support tools and a theorem prover. It is
      intended to capture the state-of-the-art in mechanized formal
      methods and to be sufficiently rugged that it can be used for
      significant applications. PVS is a research prototype: it
      evolves and improves as we develop or apply new capabilities,
      and as the stress of real use exposes new requirements.


    <label id="SNePS">
    <tag/SNePS/
      <itemize>
        <item>Web site: <htmlurl 
                url="http://www.cse.buffalo.edu/sneps/" 
                name="www.cse.buffalo.edu/sneps/">
      </itemize>
     
      The long-term goal of The SNePS Research Group is the design and
      construction of a natural-language-using computerized cognitive
      agent, and carrying out the research in artificial intelligence,
      computational linguistics, and cognitive science necessary for
      that endeavor. The three-part focus of the group is on knowledge
      representation, reasoning, and natural-language understanding
      and generation. The group is widely known for its development of
      the SNePS knowledge representation/reasoning system, and Cassie,
      its computerized cognitive agent.  
     

    <label id="Soar">
    <tag/Soar/
      <itemize>
        <item>Web site: <htmlurl 
                url="http://sitemaker.umich.edu/soar"
                name="sitemaker.umich.edu/soar">
      </itemize>

     
      Soar has been developed to be a general cognitive architecture.
      We intend ultimately to enable the Soar architecture to:
      <itemize>	
        <item>work on the full range of tasks expected of an
	    intelligent agent, from highly routine to extremely difficult,
	    open-ended problems
	    <item>represent and use appropriate forms of knowledge, such as
	    procedural, declarative, episodic, and possibly iconic
	    <item>employ the full range of problem solving methods 
	    <item>interact with the outside world and 
	    <item>learn about all aspects of the tasks and its performance on them. 
      </itemize>
      In other words, our intention is for Soar to support all the
      capabilities required of a general intelligent agent.

    <label id="TCM">
    <tag/TCM/
    <itemize>
        <item>Web site: <htmlurl 
            url="http://wwwhome.cs.utwente.nl/&tilde;tcm/" 
            name="wwwhome.cs.utwente.nl/&tilde;tcm/">
        <item>FTP site: <htmlurl 
            url="ftp://ftp.cs.utwente.nl/pub/tcm/" 
            name="ftp.cs.utwente.nl/pub/tcm/">
      </itemize>

      TCM (Toolkit for Conceptual Modeling) is our suite of graphical
      editors. TCM contains graphical editors for Entity-Relationship
      diagrams, Class-Relationship diagrams, Data and Event Flow
      diagrams, State Transition diagrams, Jackson Process Structure
      diagrams and System Network diagrams, Function Refinement trees
      and various table editors, such as a Function-Entity table
      editor and a Function Decomposition table editor.  TCM is easy
      to use and performs numerous consistency checks, some of them
      immediately, some of them upon request.
     

    <label id="Yale">
    <tag/Yale/
        <itemize>
            <item>Web site: <htmlurl 
                url="http://yale.sf.net/"
                name="yale.sf.net/">
            <item>Alt Web site: <htmlurl 
                url="http://rapid-i.com/"
                name="rapid-i.com/">
        </itemize>
        
        YALE (Yet Another Learning Environment) is an environment for machine
        learning experiments. Experiments can be made up of a large number of
        arbitrarily nestable operators and their setup is described by XML
        files which can easily created with a graphical user interface.
        Applications of YALE cover both research and real-world learning tasks.


    <label id="WEKA">
    <tag/WEKA/ 
      <itemize>
        <item>Web site: <htmlurl
            url="http://www.cs.waikato.ac.nz/&tilde;ml/"
            name="lucy.cs.waikato.ac.nz/&tilde;ml/">
      </itemize>
    
     
      WEKA (Waikato Environment for Knowledge Analysis) is an
      state-of-the-art facility for applying machine learning
      techniques to practical problems. It is a comprehensive software
      "workbench" that allows people to analyse real-world data. It
      integrates different machine learning tools within a common
      framework and a uniform user interface. It is designed to
      support a "simplicity-first" methodology, which allows users to
      experiment interactively with simple machine learning tools
      before looking for more complex solutions.
     

  </descrip>
     
     
    
